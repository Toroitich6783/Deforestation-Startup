{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f79f90d9",
   "metadata": {},
   "source": [
    "<!-- ## SMALL-SCALE CROP-MAPPING(Food security) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44ca858",
   "metadata": {},
   "source": [
    "<center><h1>MANGROVE APPLICATION</h1> </center>\n",
    "<center> <h3>“If there are no mangroves, then the sea will have no meaning. It's like a tree with no roots, for the mangroves are the roots of the sea!” Earth's mother nature</h3> </center>\n",
    "<center><img src=\"healthimage.jpg\" style=\"border-radius: 40%\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b526208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages used:\n",
    "#Uncomment and install the packages below via your terminal\n",
    "#!pip install geopandas\n",
    "#!pip install geemap\n",
    "#!pip install pip install rw-dynamicworld-cd==0.0.1\n",
    "\n",
    "#Importation of variAous Libraries or packages...\n",
    "import os\n",
    "from os import path as op\n",
    "import geopandas as gdp\n",
    "import geemap\n",
    "import ee\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "import ast\n",
    "\n",
    "\n",
    "# Making module or packages collection attribute became callable..\n",
    "import collections\n",
    "collections.Callable = collections.abc.Callable\n",
    "\n",
    "#plotting packages\n",
    "import pandas as pd#Used for data analysis also include DataFrame df data structure\n",
    "import matplotlib.pyplot as plt#For plotting of dataframes\n",
    "import numpy as np\n",
    "import altair as alt#declarative visualization(Used for charting)\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from bqplot import pyplot as plt\n",
    "from ipyleaflet import WidgetControl\n",
    "from ipywidgets import HTML\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import AppLayout\n",
    "\n",
    "from geemap import chart #for chart plotting\n",
    "\n",
    "\n",
    "#packages used in database connection.\n",
    "import pandas.io.sql as sqlio\n",
    "import psycopg2 as ps\n",
    "\n",
    "#Main function is to out various warning that might arise such as new upadates in package version\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Download wri_change_dection from https://pypi.org/project/rw-dynamicworld-cd/0.0.1/ \n",
    "#!pip install pip install rw-dynamicworld-cd==0.0.1\n",
    "from wri_change_detection import preprocessing as npv\n",
    "from wri_change_detection import gee_classifier as gclass\n",
    "from wri_change_detection import post_classification_filters as pcf\n",
    "\n",
    "Map=geemap.Map()\n",
    "from geemap import Map\n",
    "from ipywidgets import Button, Layout\n",
    "\n",
    "map_layout= Map(layout=Layout(height='100px'))\n",
    "map_layout.setCenter(18.69537526288062\n",
    ", -1.5612625039375616,9)\n",
    " \n",
    "map_layout.add_basemap(basemap='HYBRID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0088ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting various buttons for the final dsplay of the results and the output widgets or setting the intractive keys\n",
    "style = {'description_width': 'initial'}\n",
    "#General output widget\n",
    "output_widget = widgets.Output(layout={'border': '1px solid red','align-items':'center','background-color':'red'})\n",
    "\n",
    "#Widget used to display crop health\n",
    "output_widget_health = widgets.Output(layout={'border': '1px solid black','marginright':'150px'})\n",
    "\n",
    "#General output control tool.\n",
    "output_control = WidgetControl(widget=output_widget, position='topright')\n",
    "#Map output control\n",
    "map_layout.add_control(output_control)\n",
    "\n",
    "#BUTTONS  and TEXT SECTION \n",
    "#styling method that can be used-----'primary', 'success', 'info', 'warning', 'danger',)\n",
    "\n",
    "#AOI Area of Interest Selection of study area.\n",
    "AOI = widgets.Button(\n",
    "    description='Drawn Study Area',\n",
    "    button_style='success',\n",
    "    tooltip='Draw you boundaries',\n",
    "    style=style\n",
    ")\n",
    "\n",
    "\n",
    "Image_Preprocessing = widgets.Button(\n",
    "    description='Image Preprocessing',\n",
    "    button_style='info',\n",
    "    tooltip='Image Preprocessing process',\n",
    "    style=style\n",
    ")\n",
    "Update_Mask = widgets.Button(\n",
    "    description='Mask Mangrove',\n",
    "    button_style='danger',\n",
    "    tooltip='Mask Mangrove forest',\n",
    "    style=style\n",
    ")\n",
    "\n",
    "load_model = widgets.Button(\n",
    "    description='Classification & Training points',\n",
    "    button_style='primary',\n",
    "    tooltip='Random sampling of points of training points used to derive mangrove and Non-Mangrove forest',\n",
    "    style=style\n",
    ")\n",
    "\n",
    "Export_data = widgets.Button(\n",
    "    description='Calculate Mean',\n",
    "    button_style='success',\n",
    "    tooltip='Generate Mean Value',\n",
    "    style=style\n",
    ")\n",
    "GPP_EXECUTE = widgets.Button(\n",
    "    description='Map Mangrove Forest',\n",
    "    button_style='warning',\n",
    "    tooltip='Gross primary product calculatation',\n",
    "    style=style\n",
    ")\n",
    "\n",
    "Reset_button= widgets.Button(\n",
    "    description='Reset',\n",
    "    button_style='danger',\n",
    "    tooltip='reset by use of this button',\n",
    "    style=style\n",
    ")\n",
    "Data_Input = widgets.Button(\n",
    "    description='Predict Deforestation',\n",
    "    button_style='info',\n",
    "    tooltip='Predict Deforestation',\n",
    "    style=style\n",
    ")\n",
    "\n",
    "ND_execute = widgets.Button(\n",
    "    description='General Analysis',\n",
    "    button_style='primary',\n",
    "    tooltip='General Analysis',\n",
    "    style=style\n",
    ")\n",
    "\n",
    "LULCC = widgets.Button(\n",
    "    description='Dynamic LULC',\n",
    "    button_style='info',\n",
    "    tooltip='Dynamic Worlds',\n",
    "    style=style\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44be37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_widget88 = widgets.Output(layout={'border': '1px solid black'})\n",
    "output_control88 = WidgetControl(widget=output_widget88, position='bottomright')\n",
    "map_layout.add_control(output_control88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab35e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {'description_width': 'initial'}\n",
    "uploader = widgets.FileUpload(\n",
    "    description='Upload data',\n",
    "    accept='.zip, .json, .geojson',\n",
    "    multiple=False,\n",
    "    button_style='primary',\n",
    "    style=style,\n",
    ")\n",
    "\n",
    "submit = widgets.Button(\n",
    "    description='Display data', button_style='success', tooltip='Click me', style=style\n",
    ")\n",
    "\n",
    "reset = widgets.Button(\n",
    "    description='Reset', button_style='warning', tooltip='Click me', style=style\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a4e587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with output_widget88:\n",
    "    print('Upload shapefile or \\ngeojson as a zip file')\n",
    "    display(uploader)\n",
    "    display(submit)\n",
    "    display(reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f441c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(upload_widget, out_dir=None):\n",
    "\n",
    "    import zipfile\n",
    "    import glob\n",
    "\n",
    "    if out_dir is None:\n",
    "        out_dir = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    vector = None\n",
    "\n",
    "    try:\n",
    "        [uploaded_file] = upload_widget.value\n",
    "        file = upload_widget.value[uploaded_file]\n",
    "        name = file['metadata']['name']\n",
    "        content = file['content']\n",
    "        out_file = os.path.join(out_dir, name)\n",
    "        with open(out_file, \"wb\") as fp:\n",
    "            fp.write(content)\n",
    "\n",
    "        if name.endswith('.zip'):\n",
    "            with zipfile.ZipFile(out_file, \"r\") as zip_ref:\n",
    "                extract_dir = os.path.join(\n",
    "                    out_dir, name[:-4] + \"_\" + geemap.random_string(3)\n",
    "                )\n",
    "                zip_ref.extractall(extract_dir)\n",
    "                files = glob.glob(extract_dir + '/*.shp')\n",
    "                if len(files) > 0:\n",
    "                    shp = files[0]\n",
    "                    vector = geemap.shp_to_ee(shp)\n",
    "                else:\n",
    "                    files = glob.glob(extract_dir + '/*.geojson')\n",
    "                    if len(files) > 0:\n",
    "                        geojson = files[0]\n",
    "                        vector = geemap.geojson_to_ee(geojson)\n",
    "        else:\n",
    "            vector = geemap.geojson_to_ee(out_file)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "692871d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_clicked(b):\n",
    "    if uploader._counter > 0:\n",
    "        map_layout.default_style = {'cursor': 'wait'}\n",
    "        try:\n",
    "            fc = get_vector(uploader)\n",
    "            layer_name = 'Layer ' + geemap.random_string(3)\n",
    "            map_layout.addLayer(fc, {}, layer_name)\n",
    "            map_layout.centerObject(fc)\n",
    "            uploader.value.clear()\n",
    "            uploader._counter = 0\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        map_layout.default_style = {'cursor': 'pointer'}\n",
    "\n",
    "\n",
    "submit.on_click(submit_clicked)\n",
    "\n",
    "\n",
    "def reset_clicked(b):\n",
    "\n",
    "    map_layout.layers = map_layout.layers[:3]\n",
    "    output_widget88.clear_output()\n",
    "    with output_widget88:\n",
    "        print('Upload shapefile or \\ngeojson as a zip file')\n",
    "        display(uploader)\n",
    "        display(submit)\n",
    "        display(reset)\n",
    "    uploader.value.clear()\n",
    "    uploader._counter = 0\n",
    "reset.on_click(reset_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f305f546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#User instructions manual.\n",
    "instructions=widgets.Dropdown(\n",
    "    options=['Please follow this steps sequentially',\n",
    "             '1.Drawn study area or upload',\n",
    "             '2.Carry out image pre-processing',\n",
    "             '3.Map Mangrove',\n",
    "             '4.Mask out Mangrove',\n",
    "             '5.Image classification',\n",
    "             '6.Alternatively use Dynamic World for image classification(if you want to work with another study area)',\n",
    "             '7.Mangrove Analysis and prediction',\n",
    "             '8.Reset Map'],\n",
    "    value='Please follow this steps sequentially',\n",
    "    description='Instruction:',\n",
    "    disabled=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6dcd0fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e4b377226146399d2d8f0f5085b1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AppLayout(children=(VBox(children=(Map(center=[-1.5612625039375616, 18.69537526288062], controls=(WidgetContro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Arrange the layout\n",
    "from ipywidgets import AppLayout\n",
    "verticalBox = output_widget\n",
    "vBox1 = widgets.VBox([map_layout])\n",
    "\n",
    "\n",
    "vBox2 = widgets.VBox([instructions,AOI, Image_Preprocessing,GPP_EXECUTE,Update_Mask,load_model,LULCC,ND_execute,Data_Input,Reset_button])\n",
    "\n",
    "AppLayout(header=None,\n",
    "          left_sidebar=vBox1,\n",
    "          right_sidebar=vBox2,\n",
    "          footer=None,\n",
    "          step= 1,\n",
    "          pane_widths=[3, 3, 1],\n",
    "          pane_heights=[1, 1, '100%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e8dea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trial to avoid printing error in the code but a message to the user\n",
    "def AOI_clicked(b):\n",
    "        with output_widget:\n",
    "#             output_widget.clear_output()\n",
    "           \n",
    "            try:\n",
    "                global boundaries\n",
    "                \n",
    "                boundaries=map_layout.user_rois\n",
    "                \n",
    "#                 boundaries=ee.FeatureCollection(\"projects/ee-mosongjnvscode/assets/Mangrove_region_assets\")\n",
    "\n",
    "            \n",
    "                map_layout.addLayer(boundaries,{},\"Region of Intrest\")\n",
    "              \n",
    "         \n",
    "            except Exception as e:\n",
    "                print('Please select Your area of Interest.....')\n",
    "            else:\n",
    "                print(\"Successfully drawn your Region of Interest \")\n",
    "                output_widget.clear_output()\n",
    "        \n",
    "AOI.on_click(AOI_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f218471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trial to avoid printing error in the code but a message to the user\n",
    "def AOI_clicked(b):\n",
    "        with output_widget:\n",
    "            map_layout.remove_legends() \n",
    "            map_layout.remove_colorbars()\n",
    "            \n",
    "            global npp\n",
    "            npp=ee.ImageCollection(\"MODIS/006/MOD17A3H\")\n",
    "            global gpp\n",
    "            gpp=ee.ImageCollection(\"MODIS/006/MYD17A2H\")\n",
    "            map_layout.addLayer(boundaries,{},\"boundaries\")\n",
    "#             map_layout.centerObject(boundaries,17)\n",
    "            \n",
    "            \n",
    "            # Retrive dataset as a collection of images from Earth Engine Catalog\n",
    "            global mangrove_images_landsat\n",
    "            mangrove_images_landsat = ee.ImageCollection('LANDSAT/MANGROVE_FORESTS')\n",
    "            \n",
    "            mangrove_images_landsat = mangrove_images_landsat.first().clip(boundaries )\n",
    "            \n",
    "            mangrovesVis = {\n",
    "                min: 0,\n",
    "                max: 1.0,\n",
    "                'palette': ['22f302'],\n",
    "            }\n",
    "            \n",
    "            map_layout.addLayer(mangrove_images_landsat, mangrovesVis, 'Mangroves')\n",
    "            \n",
    "GPP_EXECUTE.on_click(AOI_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e643a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click event handler for Image processing process e.g landsat data\n",
    "\n",
    "def preprocess_img_clicked(b):\n",
    "     with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            \n",
    "            # select year\n",
    "            year = 2016\n",
    "            \n",
    "            global landsat_image\n",
    "            landsat_image = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR') \\\n",
    "            .filterBounds(boundaries) \\\n",
    "            .filterDate(f'{year}-01-01', f'{year}-12-31') \\\n",
    "            .select('B[1-7]') \\\n",
    "            .sort('CLOUD_COVER') \\\n",
    "            .median()\\\n",
    "            .clip(boundaries)\n",
    "            \n",
    "            vis_params = {\n",
    "                'min': 0,\n",
    "                'max': 3000,\n",
    "                'bands': ['B4', 'B3', 'B2']\n",
    "            }\n",
    "#             map_layout.centerObject(boundaries, 12)\n",
    "#             map_layout.addLayer(boundaries,{},\"boundaries\")\n",
    "            map_layout.addLayer(landsat_image, vis_params, \"Landsat-8\")\n",
    "        \n",
    "Image_Preprocessing.on_click(preprocess_img_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc8a5d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Masking mangrove forest\n",
    "def AOI_clicked(b):\n",
    "    with output_widget:\n",
    "        output_widget.clear_output()\n",
    "        global mangrove_mask\n",
    "        mangrove_mask = landsat_image.updateMask(mangrove_images_landsat.eq(1))\n",
    "        global non_mangrove_mask\n",
    "        non_mangrove_mask = landsat_image.updateMask(mangrove_mask.unmask().Not())\n",
    "        map_layout.addLayer(mangrove_mask, {'min': 0, 'max': 10000, 'bands': ['B1']}, 'mangrove mask', True)\n",
    "    \n",
    "Update_Mask.on_click(AOI_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21a9c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Masking mangrove forest\n",
    "def load_model_clicked(b):\n",
    "    \n",
    "    with output_widget:\n",
    "        output_widget.clear_output()\n",
    "        try:\n",
    "                mangrove_training_pts = mangrove_mask.sample(**{\n",
    "    'region': mangrove_mask.geometry(),\n",
    "    'scale': 30,\n",
    "    'numPixels': 10000,\n",
    "    'seed': 5343,\n",
    "    'geometries': True})\n",
    "# non_mangrove_training_pts \n",
    "                non_mangrove_training_pts = non_mangrove_mask.sample(**{\n",
    "    'region': non_mangrove_mask.geometry(),\n",
    "    'scale': 30,\n",
    "    'numPixels': 5000,\n",
    "    'seed': 0,\n",
    "    'geometries': True})\n",
    "                vis_params = {\n",
    "    'min': 0,\n",
    "    'max': 100,\n",
    "    'bands': ['B4']}\n",
    "                mangrove_color = 'eb0000'\n",
    "                non_mangrove_color = '1c5f2c'\n",
    "        \n",
    "#         map_layout.addLayer(mangrove_mask, {'min': 0, 'max': 10000, 'bands': ['B1']}, 'mangrove mask', True)\n",
    "                map_layout.addLayer(mangrove_training_pts, {'color': mangrove_color}, 'Mangrove Sample')\n",
    "                map_layout.addLayer(non_mangrove_mask, {}, 'non mangrove mask', True)\n",
    "                map_layout.addLayer(non_mangrove_training_pts, {'color': non_mangrove_color}, 'non mangrove training', True)\n",
    "        except Exception as e:\n",
    "            print('Polygon too large to be randomly sampled. Must be smaller than a hemisphere..JUST CCONTINUE!!!.. This processs simple isolate the training points for mangrove and Non-mangrove.')\n",
    "        else:\n",
    "            print(\"Successfully run the model....\")\n",
    "load_model.on_click(load_model_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5868b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trial to avoid printing error in the code but a message to the user\n",
    "def AOI_clicked(b):\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            forestChange = ee.Image(\"UMD/hansen/global_forest_change_2019_v1_7\")\n",
    "            global projection_ee\n",
    "            projection_ee = forestChange.projection()\n",
    "            projection = projection_ee.getInfo()\n",
    "            crs = projection.get('crs')\n",
    "            crsTransform = projection.get('transform')\n",
    "            scale = projection_ee.nominalScale().getInfo()\n",
    "            \n",
    "            countryBoundaries = ee.FeatureCollection('projects/resource-watch-gee/gadm36_0')\n",
    "            global DRCBoundary\n",
    "            DRCBoundary = countryBoundaries.filterMetadata('GID_0','equals','COD').first().geometry()\n",
    "            \n",
    "            primaryForest = ee.Image('UMD/GLAD/PRIMARY_HUMID_TROPICAL_FORESTS/v1/2001')\n",
    "\n",
    "# select tree cover loss band and unmask with value 0 to represent no loss\n",
    "            tclYear = forestChange.select(['lossyear']).unmask(0)\n",
    "\n",
    "# define mask of primary forest areas\n",
    "            primaryForestValid = primaryForest.eq(1);\n",
    "# define mask for where Hansen data is valid\n",
    "            forestChangeValid = forestChange.select('datamask').eq(1)\n",
    "# define mask of tree cover loss > 30%\n",
    "            forestCoverValid = forestChange.select('treecover2000').gte(30)\n",
    "\n",
    "# create final mask where (primaryForestValid = 1) AND (forestChangeValid = 1) AND (forestCoverValid = 1)\n",
    "            treeCoverLossValid = primaryForestValid.bitwiseAnd(forestCoverValid).bitwiseAnd(forestChangeValid)\n",
    "\n",
    "# update tree cover loss year to mask invalid areas\n",
    "            tclYearMasked = tclYear.updateMask(treeCoverLossValid)\n",
    "# now tclYearMasked = {0 when tree cover loss did not occur, 1-19 for year when tree cover loss occured} only in valid areas\n",
    "            tclPalette = ['#0051ff',\n",
    "            '#f7f4f9','#f7f4f9',\n",
    "            '#e7e1ef','#e7e1ef',\n",
    "            '#d4b9da','#d4b9da',\n",
    "            '#c994c7','#c994c7',\n",
    "            '#df65b0','#df65b0',\n",
    "            '#e7298a','#e7298a',\n",
    "            '#ce1256','#ce1256',\n",
    "            '#980043','#980043',\n",
    "            '#67001f','#67001f']\n",
    "            tclViz = {'min': 0, 'max': 19, 'palette': tclPalette}\n",
    "#             map_layout.addLayer(forestChangeValid.updateMask(forestChangeValid).clip(boundaries),\n",
    "#               {'min': 0, 'max': 1, 'palette': ['#f9261b','#5a1bf9']},name='Hansen Valid')\n",
    "#             map_layout.addLayer(forestCoverValid.updateMask(forestCoverValid).clip(boundaries),\n",
    "#               {'min': 0, 'max': 1, 'palette': ['#f7f91b','#28ce4c']},name='Tree Cover > 30')\n",
    "            map_layout.addLayer(primaryForestValid.updateMask(primaryForestValid).clip(boundaries),\n",
    "              {'min': 0, 'max': 1, 'palette': ['#f9801b','#39d6d2']},name='Primary Forest')\n",
    "#             map_layout.addLayer(forestChange.select(['lossyear']).clip(boundaries),tclViz,name='Tree Cover Loss UnMasked')\n",
    "#             map_layout.addLayer(tclYearMasked.clip(boundaries),tclViz,name='Tree Cover Loss Masked')\n",
    "            global tclEarlyLoss\n",
    "            tclEarlyLoss = tclYearMasked.expression(\n",
    "    '(year>0 && year<12)', {\n",
    "      'year': tclYearMasked.select('lossyear')})\n",
    "# Define mask when tree cover occurred after 2017\n",
    "            tclLaterLoss = tclYearMasked.expression(\n",
    "    '(year>17)', {\n",
    "      'year': tclYearMasked.select('lossyear')\n",
    "})\n",
    "\n",
    "# Define binary variable for tree cover loss that occurred from 2012 through 2017,\n",
    "# loss that occurred after 2017 is marked as 0\n",
    "            global tclReferenceLoss\n",
    "            tclReferenceLoss = tclYearMasked.expression(\n",
    "    '(year>11 && year<18) ? 1 : 0', {\n",
    "      'year': tclYearMasked.select('lossyear')})\n",
    "\n",
    "# Define mask for tree cover loss that occurred from 2012 through 2017\n",
    "            global referenceTreeCoverLossValid\n",
    "            referenceTreeCoverLossValid = treeCoverLossValid.bitwiseAnd(tclEarlyLoss.eq(0))\n",
    "\n",
    "# Mask tree cover loss years to get binary 0 for no tree cover loss and 1 for \n",
    "            tclReferenceLoss = tclReferenceLoss.updateMask(referenceTreeCoverLossValid).gt(0)\n",
    "            tclReferenceLoss = tclReferenceLoss.rename('loss')\n",
    "\n",
    "# Map layers to double check!\n",
    "#             map_layout.addLayer(tclYearMasked,tclViz,name='Tree Cover Loss Masked')\n",
    "            map_layout.addLayer(tclEarlyLoss.clip(boundaries),{'min': 0, 'max': 1, 'palette': ['#29d619','#FF0000']},name='Early Loss')\n",
    "#             map_layout.addLayer(tclLaterLoss.clip(boundaries),{'min': 0, 'max': 1, 'palette': ['#f9261b','#5a1bf9']},name='Later Loss')\n",
    "#             map_layout.addLayer(tclReferenceLoss,{'min': 0, 'max': 1, 'palette': ['#f9261b','#5a1bf9']},name='Historical Loss')   \n",
    "            map_layout.remove_legends()\n",
    "            legend_dict = {\n",
    "        'Early Loss': 'FF0000',\n",
    "       'Reserved Areas': '29d619',\n",
    "            'Primary Cover':'39d6d2'}\n",
    "            map_layout.add_legend(legend_title=\"Readings\", legend_dict=legend_dict)\n",
    "\n",
    "\n",
    "ND_execute.on_click(AOI_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d85a1c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffd4d21897e4fed82ebbc8379783252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid green'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creation of an output widgets to ouput outside the map.\n",
    "user_out = widgets.Output(layout={'border': '1px solid green'})\n",
    "user_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cce9e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Trial to avoid printing error in the code but a message to the user\n",
    "def AOI_clicked(b):\n",
    "        with user_out:\n",
    "#             output_widget.clear_output()\n",
    "           \n",
    "            try:\n",
    "        \n",
    "                  \n",
    "#Extract Gross primary Product(GPP)\n",
    "                out_dir = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "                out_gppCollection_stats = os.path.join(out_dir, 'GPP_Mean_Value.csv')\n",
    "                \n",
    "                if not os.path.exists(out_dir):\n",
    "                    os.makedirs(out_dir)\n",
    "\n",
    "                    \n",
    "# Allowed output formats: csv, shp, json, kml, kmz\n",
    "# Allowed statistics type: MEAN, MAXIMUM, MINIMUM, MEDIAN, STD, MIN_MAX, VARIANCE, SUM\n",
    "                geemap.zonal_statistics(gppCollection, boundaries, out_gppCollection_stats,statistics_type='MEAN', scale=10)\n",
    "        \n",
    "\n",
    "                out_dir = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "                ND_stats = os.path.join(out_dir, 'ND_Mean_Value.csv')\n",
    "                \n",
    "                if not os.path.exists(out_dir):\n",
    "                    os.makedirs(out_dir)\n",
    "\n",
    "                    \n",
    "# Allowed output formats: csv, shp, json, kml, kmz\n",
    "# Allowed statistics type: MEAN, MAXIMUM, MINIMUM, MEDIAN, STD, MIN_MAX, VARIANCE, SUM\n",
    "                geemap.zonal_statistics(ND, boundaries, ND_stats,statistics_type='MEAN', scale=10)\n",
    "                \n",
    "\n",
    "\n",
    "               \n",
    "            except Exception as e:\n",
    "                print('Please their is a chance that you may skip a step...')\n",
    "            else:\n",
    "                print(\"Successfully run the model....\")\n",
    "                \n",
    "Export_data.on_click(AOI_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0a55497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather training, testing, and validation points\n",
    "def predict_clicked(b):\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            global num_seed\n",
    "            num_seed = 30\n",
    "#We'll remove training points that are within a certain distance to the validation and test points\n",
    "            distanceToFilter = 10000\n",
    "            numPoints = 6000\n",
    "\n",
    "#Sample point locations that we will split into training, validation, and test sets\n",
    "            point_locations = npv.getStratifiedSampleBandPoints(tclReferenceLoss, region=DRCBoundary, \n",
    "                                                       numPoints=numPoints, bandName='loss',seed=num_seed,\n",
    "                                                       geometries=True, projection=projection_ee)\n",
    "\n",
    "#Assign random value between 0 and 1 to split into training, validation, and test sets\n",
    "            point_locations = point_locations.randomColumn(columnName='TrainingSplit', seed=num_seed)\n",
    "#First split training set from the rest, taking 70% of the points for training\n",
    "#Roughly 70% training, 30% for validation + testing\n",
    "            training_split = 0.7\n",
    "            training_locations = point_locations.filter(ee.Filter.lt('TrainingSplit', training_split))\n",
    "            validation_and_test = point_locations.filter(ee.Filter.gte('TrainingSplit', training_split))\n",
    "\n",
    "#Define distance filter to remove training points within a certain distance of test points and validation points\n",
    "            distFilter = ee.Filter.withinDistance(distance=distanceToFilter, leftField='.geo', rightField= '.geo', maxError= 1)\n",
    "            join = ee.Join.inverted()\n",
    "            training_locations = join.apply(training_locations, validation_and_test, distFilter);\n",
    "\n",
    "#Assign another random value between 0 and 1 to validation_and_test to split to validation and test sets\n",
    "            validation_and_test = validation_and_test.randomColumn(columnName='ValidationSplit', seed=num_seed)\n",
    "#Of the 30% saved for validation + testing, half goes to validation and half goes to test\n",
    "#Meaning original sample will be 70% training, 15% validation, 15% testing\n",
    "            validation_split = 0.5 \n",
    "            validation_locations = validation_and_test.filter(ee.Filter.lt('ValidationSplit', validation_split))\n",
    "            test_locations = validation_and_test.filter(ee.Filter.gte('ValidationSplit', validation_split))\n",
    "\n",
    "#Apply distance filter to remove validation points within a certain distance of test points\n",
    "            validation_locations = join.apply(validation_locations, test_locations, distFilter);\n",
    "\n",
    "#Export these locations to an Earth Engine asset\n",
    "            location_description = '{}_locations'\n",
    "# location_assetID = 'users/listerkristineanne/CongoDeforestation/TrainingPoints_{}_locations'\n",
    "# \"projects/ee-mosongjnvscode/assets\"\n",
    "            location_assetID=\"users/MosongJrn/TrainingPoints_{}_locations\"\n",
    "\n",
    "#Export results to GEE\n",
    "#             export_results_task = ee.batch.Export.table.toAsset(\n",
    "#                 collection=training_locations, \n",
    "#                 description = location_description.format('training'), \n",
    "#                 assetId = location_assetID.format('training'))\n",
    "#             export_results_task.start()\n",
    "    \n",
    "#             export_results_task = ee.batch.Export.table.toAsset(\n",
    "#                 collection=validation_locations, \n",
    "#                 description = location_description.format('validation'), \n",
    "#                 assetId = location_assetID.format('validation'))\n",
    "#             export_results_task.start()\n",
    "\n",
    "#             export_results_task = ee.batch.Export.table.toAsset(\n",
    "#                 collection=test_locations, \n",
    "#                 description = location_description.format('test'), \n",
    "#                 assetId = location_assetID.format('test'))\n",
    "#             export_results_task.start()\n",
    "            \n",
    "#             while export_results_task.active():\n",
    "#                 print('Polling for task (id: {}).'.format(export_results_task.id))\n",
    "#                 time.sleep(30)\n",
    "# Define predictor variables\n",
    "# Load elevation\n",
    "            elevation = ee.Image(\"CGIAR/SRTM90_V4\")\n",
    "# Calculate slope\n",
    "            slope = ee.Terrain.slope(elevation)\n",
    "\n",
    "# Load roads data\n",
    "            roads = ee.FeatureCollection('projects/ee-mosongjnvscode/assets/COG_roads')\n",
    "\n",
    "# Create cost map for measuring distance, for now we'll list crossing any pixel as the same weight\n",
    "# Generate a constant image with value 1, clip it to the bounds of the DRC\n",
    "            cost = ee.Image.constant(1).clip(DRCBoundary.bounds())\n",
    "            maxDistance=50000\n",
    "\n",
    "# Calculate distance to loss from 2001 to 2011\n",
    "# First unmask earlyLoss to get target pixels\n",
    "            earlyLossUnmasked = tclEarlyLoss.unmask(0)\n",
    "            distanceToEarlyLoss = cost.cumulativeCost(source= earlyLossUnmasked, maxDistance=maxDistance).rename('earlyLossDistance')\n",
    "            distanceToEarlyLoss = distanceToEarlyLoss.unmask(maxDistance)\n",
    "\n",
    "# Burn roads feature collection to image\n",
    "            roads = roads.map(lambda x: x.set({'constant':1}))\n",
    "            roadsImage = roads.reduceToImage(['constant'], ee.Reducer.first())\n",
    "# Convert image to binary 0:1 if there is a road\n",
    "            roadsImage = roadsImage.unmask(0)\n",
    "# Calculate distance to roads\n",
    "            distanceToRoads = cost.cumulativeCost(source= roadsImage, maxDistance=maxDistance).rename('roadsDistance')\n",
    "            distanceToRoads = distanceToRoads.unmask(maxDistance)\n",
    "\n",
    "# Define list of predictor variable images and convert to a single image\n",
    "            predictor_variable_list = [distanceToEarlyLoss,distanceToRoads,elevation,slope]\n",
    "            predictor_variable_image = ee.ImageCollection(predictor_variable_list).toBands()\n",
    "\n",
    "# Rename bands\n",
    "            predictor_variable_names = ['earlyLossDistance','roadsDistance','elevation','slope']\n",
    "            predictor_variable_image = predictor_variable_image.rename(predictor_variable_names)\n",
    "        \n",
    "#Define properties to export to an Earth Engine asset\n",
    "            points_description = '{}_points'\n",
    "# points_assetID = 'users/listerkristineanne/CongoDeforestation/TrainingPoints_{}_points'\n",
    "            points_assetID=\"users/MosongJrn/TrainingPoints_{}_points\"\n",
    "\n",
    "\n",
    "# Load the point locations assets\n",
    "            training_locations_asset = ee.FeatureCollection(location_assetID.format('training'))\n",
    "            validation_locations_asset = ee.FeatureCollection(location_assetID.format('validation'))\n",
    "            test_locations_asset = ee.FeatureCollection(location_assetID.format('test'))\n",
    "\n",
    "# Sample predictor variable at location\n",
    "            training_points = predictor_variable_image.sampleRegions(training_locations_asset, \n",
    "                                                         projection=projection_ee, geometries=True,tileScale=16)\n",
    "            validation_points = predictor_variable_image.sampleRegions(validation_locations_asset, \n",
    "                                                           projection=projection_ee, geometries=True,tileScale=16)\n",
    "            test_points = predictor_variable_image.sampleRegions(test_locations_asset, \n",
    "                                                     projection=projection_ee, geometries=True,tileScale=16)\n",
    "\n",
    "# # # Export results\n",
    "#             export_results_task = ee.batch.Export.table.toAsset(\n",
    "#                 collection=training_points,\n",
    "#                 description = points_description.format('training'),\n",
    "#                 assetId = points_assetID.format('training'))\n",
    "#             export_results_task.start()\n",
    "\n",
    "#             export_results_task = ee.batch.Export.table.toAsset(\n",
    "#                 collection=validation_points,\n",
    "#                 description = points_description.format('validation'),\n",
    "#                 assetId = points_assetID.format('validation'))\n",
    "#             export_results_task.start()\n",
    "\n",
    "#             export_results_task = ee.batch.Export.table.toAsset(\n",
    "#                 collection=test_points,\n",
    "#                 description = points_description.format('test'),\n",
    "#                 assetId = points_assetID.format('test'))\n",
    "#             export_results_task.start()\n",
    "            \n",
    "#             while export_results_task.active():\n",
    "#                 print('Polling for task (id: {}).'.format(export_results_task.id))\n",
    "#                 time.sleep(30)\n",
    "# Define model parameters to test\n",
    "#Define dictionaries of parameters and models to test\n",
    "#You can find the inputs for the parameters under the ee.Classifiers section of GEE\n",
    "\n",
    "            rf_parameters = {'seed':[num_seed],\n",
    "                             'numberOfTrees': [50,100],\n",
    "                             'variablesPerSplit': [1,2,None], \n",
    "                             'minLeafPopulation': [4,10,50], \n",
    "                             'bagFraction': [None,0.5,.3], \n",
    "                              'maxNodes': [None, 20, 50]\n",
    "                            }\n",
    "#buildGridSearchList converts the parameter dictionary into a list of classifiers that can be used in cross-validation\n",
    "            rf_classifier_list = gclass.buildGridSearchList(rf_parameters,'smileRandomForest')\n",
    "\n",
    "            svm_parameters = {'decisionProcedure':[None]}\n",
    "            svm_classifier_list = gclass.buildGridSearchList(svm_parameters,'libsvm')\n",
    "\n",
    "#maxent_parameters = {'minIterations':[10,100],'maxIterations':[50,200]}\n",
    "#maxent_classifier_list = gclass.buildGridSearchList(maxent_parameters,'gmoMaxEnt')\n",
    "\n",
    "            classifier_list = rf_classifier_list+svm_classifier_list#+maxent_classifier_list\n",
    "# Use cross-validation to test models\n",
    "\n",
    "#Name y_column\n",
    "            y_column = 'loss'\n",
    "\n",
    "#Define assetId and description format to export to GEE\n",
    "\n",
    "            cv_results_assetId=\"users/MosongJrn/CV_Results_20210305\"\n",
    "\n",
    "# cv_results_assetId = 'users/listerkristineanne/CongoDeforestation/TrainingPoints/CV_Results_20210305'\n",
    "            cv_results_description = 'cv_export_20210305'\n",
    "\n",
    "#Load training points\n",
    "            training_points = ee.FeatureCollection(points_assetID.format('training'))\n",
    "\n",
    "#Perform cross validation, returns a feature collection\n",
    "            cv_results = gclass.kFoldCrossValidation(inputtedFeatureCollection = training_points, \n",
    "                                     propertyToPredictAsString = y_column, \n",
    "                                     predictors = predictor_variable_names, \n",
    "                                     listOfClassifiers = classifier_list,\n",
    "                                     k=3,seed=num_seed)\n",
    "# Export results to GEE\n",
    "#             export_results_task = ee.batch.Export.table.toAsset(\n",
    "#                 collection=cv_results,\n",
    "#                 description = cv_results_description,\n",
    "#                 assetId = cv_results_assetId)\n",
    "#             export_results_task.start()\n",
    "        \n",
    "        \n",
    "#             while export_results_task.active():\n",
    "#                 print('Polling for task (id: {}).'.format(export_results_task.id))\n",
    "#                 time.sleep(30)\n",
    "\n",
    "# Evaluate accuracy of models on validation set\n",
    "\n",
    "#Create empty dataframe to save results of cross validation\n",
    "            accuracy_and_keys = pd.DataFrame()\n",
    "\n",
    "#Load cross-validation results\n",
    "            results = ee.FeatureCollection(cv_results_assetId)\n",
    "#Get the best result by the cross validation score\n",
    "            best_result = results.sort('Validation Score', False).first()\n",
    "\n",
    "#Load params as a dictionary\n",
    "            params = best_result.get('Params').getInfo()\n",
    "            params = ast.literal_eval(params)\n",
    "\n",
    "#Get the calssifier name\n",
    "            classifierName = best_result.get('Classifier Type').getInfo()\n",
    "\n",
    "#Load classifier with best params\n",
    "            best_model = gclass.defineClassifier(params,classifierName)\n",
    "\n",
    "#Load training and validation points\n",
    "            training_points = ee.FeatureCollection(points_assetID.format('training'))\n",
    "            validation_points = ee.FeatureCollection(points_assetID.format('validation'))\n",
    "\n",
    "#Train a classifier with the best params on the training data\n",
    "            best_model = best_model.train(training_points, classProperty=y_column, \n",
    "                              inputProperties=predictor_variable_names, subsamplingSeed=num_seed)\n",
    "\n",
    "#Predict over validation data\n",
    "            validation_points_predicted = validation_points.classify(best_model)\n",
    "\n",
    "#Get confusion matrix and accuracy score\n",
    "            confusion_matrix = validation_points_predicted.errorMatrix(y_column, 'classification');\n",
    "            accuracy = confusion_matrix.accuracy().getInfo()\n",
    "\n",
    "\n",
    "#Get confusion matrix and accuracy score\n",
    "            confusion_matrix = validation_points_predicted.errorMatrix(y_column, 'classification');\n",
    "            accuracy = confusion_matrix.accuracy().getInfo()\n",
    "            print('--------------------------------------------------------------')\n",
    "            print('Final Model Validation Set Confusion Matrix')\n",
    "            print(gclass.pretty_print_confusion_matrix_binary(confusion_matrix.getInfo()))\n",
    "            print('Final Model Validation Set Accuracy',accuracy)\n",
    "            print('\\n')\n",
    "            \n",
    "            print(best_model.schema().getInfo())\n",
    "            \n",
    "#Use best model and predictor variable image to predict loss\n",
    "            predicted_loss = predictor_variable_image.updateMask(referenceTreeCoverLossValid).classify(best_model)\n",
    "\n",
    "# Map layers to double check!\n",
    "#Map3.addLayer(tclYearMasked,tclViz,name='Tree Cover Loss Masked')\n",
    "#             map_layout.addLayer(tclReferenceLoss,{'min': 0, 'max': 1, 'palette': ['#98BC47','#DA6E9A']},name='Historical Loss')\n",
    "#             map_layout.addLayer(predicted_loss,{'min': 0, 'max': 1, 'palette': ['#98BC47','#DA6E9A']},name='Predicted Loss')\n",
    "            map_layout.addLayer(tclReferenceLoss.eq(predicted_loss).clip(boundaries),{'min': 0, 'max': 1, 'palette': ['#29d619','#d63414' ]},name='Accurate Prediction')\n",
    "            map_layout.remove_legends() \n",
    "            legend_dict = {\n",
    "        'Predicted Deforestation': 'FF0000',\n",
    "       'Reserved Areas': '29d619',}\n",
    "            map_layout.add_legend(legend_title=\"Readings\", legend_dict=legend_dict)\n",
    "\n",
    "Data_Input.on_click(predict_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbce5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e382c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click event handler for Image processing process e.g sentinel data\n",
    "\n",
    "def submit_clicked(b):\n",
    "     with output_widget:\n",
    "            try:\n",
    "                output_widget.clear_output()\n",
    "                map_layout.remove_legends()\n",
    "                start_date=\"2014-01-01\"#Set start_date(yy/mon/day)\n",
    "                end_date=\"2022-03-31\"#Set End_date(yy/mon/day)\n",
    "            \n",
    "                global region # Set the region of interest by simply drawing a polygon on the map\n",
    "                region = boundaries\n",
    "                if region is None:\n",
    "                    region = ee.Geometry.BBox(-61.18116254022864,6.614609265030635, -61.18116254022864,6.769074870340775)\n",
    "\n",
    "                image = geemap.dynamic_world_s2(region, start_date, end_date)\n",
    "                vis_params3 = {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 3000}\n",
    "                global landcover\n",
    "                # Create Dynamic World land cover composite\n",
    "                landcover = geemap.dynamic_world(region, start_date, end_date, return_type='hillshade')\n",
    "\n",
    "                # Add legend to the map\n",
    "                map_layout.addLayer(landcover.clip(boundaries),{}, 'LULCC') \n",
    "                map_layout.add_legend(title=\"Land Cover\", builtin_legend='Dynamic_World')\n",
    "                \n",
    "\n",
    "            except Exception as e:\n",
    "                print('Sorry an error occurred...please try again')\n",
    "            else:\n",
    "                print(\"LULC attained successfully\")\n",
    "        \n",
    "LULCC.on_click(submit_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c439e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_me(b):\n",
    "    with output_widget:\n",
    "        output_widget.clear_output()\n",
    "        try:\n",
    "            map_layout.remove_legends() \n",
    "            map_layout.remove_colorbar()\n",
    "            map_layout.remove_drawn_features()\n",
    "            map_layout.remove_ee_layer('Dynamic_World')\n",
    "            map_layout.remove_ee_layer(\"Mangroves\")\n",
    "            map_layout.remove_ee_layer(\"Region of Intrest\")\n",
    "            map_layout.remove_ee_layer('Landsat-8')\n",
    "            map_layout.remove_ee_layer('mangrove mask')\n",
    "            map_layout.remove_ee_layer('Mangrove Sample')\n",
    "            map_layout.remove_ee_layer('non mangrove mask')\n",
    "            map_layout.remove_ee_layer('non mangrove training')\n",
    "            map_layout.remove_ee_layer('boundaries')\n",
    "            map_layout.remove_ee_layer('Hansen Valid')\n",
    "            map_layout.remove_ee_layer(\"Tree Cover > 30\")\n",
    "            map_layout.remove_ee_layer(\"Primary Forest\")\n",
    "            map_layout.remove_ee_layer('Tree Cover Loss Masked')\n",
    "            map_layout.remove_ee_layer('Early Loss')\n",
    "            map_layout.remove_ee_layer('Later Loss')\n",
    "            map_layout.remove_ee_layer('Historical Loss')\n",
    "            map_layout.remove_ee_layer('Historical Loss')\n",
    "            map_layout.remove_ee_layer('Predicted Loss')\n",
    "            map_layout.remove_ee_layer('Accurate')\n",
    "     \n",
    "        except Exception as e:\n",
    "            print(\"Sorry an error just occured\")\n",
    "        else:\n",
    "            print(\"reset successfully....\")\n",
    "\n",
    "Reset_button.on_click(reset_me)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cf6fbd",
   "metadata": {},
   "source": [
    "<h3>BackGround Documentation</h3><br>\n",
    "<h3>Global Mangrove Forests Distribution, v1 (2000)</h3>\n",
    "The database was prepared using Landsat satellite data from the year 2000. More than 1,000 Landsat scenes obtained from the USGS Earth Resources Observation and Science Center (EROS) were classified using hybrid supervised and unsupervised digital image classification techniques. This database is the first, most comprehensive mangrove assessment of the world (Giri et al., 2011). Partial funding of this research was provided by NASA.\n",
    "\n",
    "The mangrove database is being used for identifying priority areas for mangrove conservation, studying the role of mangrove forests in saving lives and properties from natural disasters (e.g. tsunami), carbon accounting, and biodiversity conservation. The USGS EROS has been using the data to study the impact of sea level rise on mangrove ecosystems. The database serves as a baseline for mangrove monitoring.<br>\n",
    "<h3>Landsat Data</h3><br>\n",
    "Landsat, a joint program of the USGS and NASA, has been observing the Earth continuously from 1972 through the present day. Today the Landsat satellites image the entire Earth's surface at a 30-meter resolution about once every two weeks, including multispectral and thermal data. The USGS produces data in 3 categories for each satellite (Tier 1, Tier 2 and RT).\n",
    "<h3>Training of the Model</h3><br>\n",
    "The trained model is basically powered  by the global forest watch which combines several varables such as the existing ditance to the roads, elevation based on the SRTM datasets,slope with is extracted from slope data, the prevoius or early forest loss a correlation relationship is created between this variables.<br>\n",
    "\n",
    "<h3>SRTM Digital Elevation Data Version 4</h3>\n",
    "The Shuttle Radar Topography Mission (SRTM) digital elevation dataset was originally produced to provide consistent, high-quality elevation data at near global scope. This version of the SRTM digital elevation data has been processed to fill data voids, and to facilitate its ease of use.\n",
    "\n",
    "<center><h5>Powered by Geemap and ipywidgets</h5></center><br>\n",
    "<center><h5>Author:@ your name.. </h5></center><br>\n",
    "<center><img src=\"healthimage.jpg\" style=\"width: 80px;border-radius: 60%;\n",
    "\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9628e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
